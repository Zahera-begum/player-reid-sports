{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc7e71c",
   "metadata": {},
   "source": [
    "### 📦 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f63a0",
   "metadata": {},
   "source": [
    "### ⚙️ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_1_PATH = 'broadcast.mp4'\n",
    "VIDEO_2_PATH = 'tacticam.mp4'\n",
    "MODEL_PATH = 'best.pt'\n",
    "OUTPUT_DIR = 'output_frames'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83152db6",
   "metadata": {},
   "source": [
    "### 🧠 Load YOLOv5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yolo = torch.hub.load('ultralytics/yolov5', 'custom', path=MODEL_PATH, force_reload=True)\n",
    "model_yolo.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5fd9c",
   "metadata": {},
   "source": [
    "### 🔍 Load ResNet18 Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model_feat = models.resnet18(pretrained=True)\n",
    "model_feat = model_feat.to(DEVICE)\n",
    "model_feat.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da12f0fb",
   "metadata": {},
   "source": [
    "### 🧩 Feature & Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        features = model_feat(image)\n",
    "    return features.view(-1).cpu().numpy()\n",
    "\n",
    "def detect_players(frame):\n",
    "    results = model_yolo(frame)\n",
    "    detections = results.xyxy[0]\n",
    "    players = []\n",
    "    for *box, conf, cls in detections:\n",
    "        if int(cls) == 0:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "            if crop.size > 0:\n",
    "                players.append(crop)\n",
    "    return players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be1999",
   "metadata": {},
   "source": [
    "### 🎥 Video Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    features_list = []\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_idx > 0:\n",
    "            break\n",
    "        players = detect_players(frame)\n",
    "        for idx, player in enumerate(players):\n",
    "            feat = extract_features(player)\n",
    "            features_list.append((f\"player_{idx}\", feat))\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc8f6f",
   "metadata": {},
   "source": [
    "### 🔗 Player Matching Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d36e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_players(features1, features2):\n",
    "    matched = {}\n",
    "    for id2, feat2 in features2:\n",
    "        similarities = [(id1, cosine_similarity([feat1], [feat2])[0][0]) for id1, feat1 in features1]\n",
    "        best_match = max(similarities, key=lambda x: x[1])\n",
    "        matched[id2] = best_match[0]\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba62027",
   "metadata": {},
   "source": [
    "### 🚀 Run Matching Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing broadcast video...\")\n",
    "features_broadcast = process_video(VIDEO_1_PATH)\n",
    "\n",
    "print(\"Processing tacticam video...\")\n",
    "features_tacticam = process_video(VIDEO_2_PATH)\n",
    "\n",
    "print(\"Matching players...\")\n",
    "matches = match_players(features_broadcast, features_tacticam)\n",
    "\n",
    "print(\"\\nMatched Player IDs:\")\n",
    "for tacticam_id, broadcast_id in matches.items():\n",
    "    print(f\"{tacticam_id} -> {broadcast_id}\")\n",
    "\n",
    "with open(\"player_id_mapping.txt\", \"w\") as f:\n",
    "    for tacticam_id, broadcast_id in matches.items():\n",
    "        f.write(f\"{tacticam_id} -> {broadcast_id}\\n\")\n",
    "\n",
    "print(\"\\nMapping saved to player_id_mapping.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
